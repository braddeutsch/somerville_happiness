{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a90c9a",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "Load data, choose year or range of year, and standardize responses. The output will be used for weighted and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1cf6fd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3978bac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('../data/raw/Somerville_Happiness_Survey_Responses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d4c2ab00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total responses: 8886\n",
      "Responses per year:       Combined_ID\n",
      "Year             \n",
      "2011         6167\n",
      "2013          193\n",
      "2015          185\n",
      "2017          845\n",
      "2019         1496\n"
     ]
    }
   ],
   "source": [
    "# Choose a year or range of years to look at\n",
    "print(\"Total responses: {}\".format(len(data)))\n",
    "print(\"Responses per year: {}\".format(data.groupby('Year').count()[['Combined_ID']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608fb107",
   "metadata": {},
   "source": [
    "Year counts are very inconsistent. A deeper look shows that in 2011 only a few questions were asked. That basically leaves us with 2019 for data analyis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b7105852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip down to 2019 only\n",
    "data_2019 = data[data['Year']==2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af2d71",
   "metadata": {},
   "source": [
    "Handle nulls. Eliminate any questions that were not asked in 2019. Replace null placeholders with np.nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d1974a30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# drop null columns. These are questions that were not asked in this yeaer\n",
    "data_2019 = data_2019.dropna(axis=1)\n",
    "\n",
    "# replace any 999.0 / 990 / '999' with null (declined to answer)\n",
    "data_2019 = data_2019.replace(999.0, np.nan)\n",
    "data_2019 = data_2019.replace(999, np.nan)\n",
    "data_2019 = data_2019.replace('999', np.nan)\n",
    "\n",
    "# rename columns for easier usage\n",
    "col_map = {'Combined_ID': 'id',\n",
    "           'Year': 'year',\n",
    "           'How.happy.do.you.feel.right.now': 'q01_happy',\n",
    "           'How.satisfied.are.you.with.your.life.in.general': 'q02_satisfied_general',\n",
    "           'How.satisfied.are.you.with.Somerville.as.a.place.to.live': 'q03_satisfied_somerville',\n",
    "           'How.satisfied.are.you.with.your.neighborhood': 'q04_satisfied_neighborhood',\n",
    "           'Do.you.feel.the.City.is.headed.in.the.right.direction.or.is.it.on.the.wrong.track': 'q05_city_direction',\n",
    "           'How.would.you.rate.the.following..The.availability.of.information.about.city.services': 'q06a_city_services',\n",
    "           'How.would.you.rate.the.following..The.cost.of.housing': 'q06b_cost_housing',\n",
    "           'How.would.you.rate.the.following..The.overall.quality.of.public.schools': 'q06c_quality_schools',\n",
    "           'How.would.you.rate.the.following..Your.trust.in.the.local.police': 'q06d_trust_police',\n",
    "           'How.would.you.rate.the.following..The.maintenance.of.streets.and.sidewalks': 'q06e_sidewalks',\n",
    "           'How.would.you.rate.the.following..The.availability.of.social.community.events': 'q06f_events',\n",
    "           'How.safe.do.you.feel.crossing.a.busy.street.in.Somerville': 'q07_safe_crossing_street',\n",
    "           'How.convenient.is.it.for.you.to.get.where.you.want.to.go': 'q08_convenient',\n",
    "           'How.safe.do.you.feel.walking.in.your.neighborhood.at.night': 'q09_safe_at_night',\n",
    "           'How.satisfied.are.you.with.the.appearance.of.parks.and.squares.in.your.neighborhood': 'q10_parks',\n",
    "           'How.satisfied.are.you.with.the.beauty.or.physical.setting.of.your.neighborhood': 'q11_beauty',\n",
    "           'How.satisfied.are.you.with.the.condition.of.your.housing': 'q12_housing_condition',\n",
    "           'What.is.your.gender': 'd01_gender',\n",
    "           'Age': 'd02_age',\n",
    "           'Language': 'd03_language',\n",
    "          'What.is.your.race.or.ethnicity': 'd04_race',\n",
    "          'Do.you.have.children.age.18.or.younger.who.live.with.you': 'd05_num_children',\n",
    "          'Describe.your.housing.status.in.Somerville': 'd06_housing_status',\n",
    "          'Do.you.plan.to.move.away.from.Somerville.in.the.next.two.years': 'd07_plan_to_move',\n",
    "          'What.is.your.annual.household.income': 'd08_hhi',\n",
    "          'Are.you.a.student': 'd09_is_student',\n",
    "           'How.long.have.you.lived.here': 'd10_how_long_lived_here',\n",
    "          'Ward': 'ward',\n",
    "          'Do.you.plan.to.move.away.from.Somerville.in.the.next.two.years.yes.why': 'move_why',\n",
    "          'What.is.your.primary.mode.of.transportation': 'd11_transportation_mode',\n",
    "          'Which.of.the.following.have.you.used.in.the.past.month.to.get.around': 'd12_transportation_month',\n",
    "          }\n",
    "\n",
    "# map column names \n",
    "data_2019.columns = data_2019.columns.map(col_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41973713",
   "metadata": {},
   "source": [
    "## Variable transformations\n",
    "1. Categorize ambigious or unique answers\n",
    "2. Map HHI, race, ethnicity, gender, age to hooks for population balancing\n",
    "3. Break out compound responses into indicators.\n",
    "\n",
    "We will retain the un-transformed variables for later feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cec90e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender\n",
    "\n",
    "def map_gender(v):\n",
    "    \"\"\"Define gender categories. There is an open entry option, which we're mapping to non-binary.\"\"\"\n",
    "    if v not in ('Female', 'Male', 'No Answer'):\n",
    "        return 'Nonbinary'\n",
    "    else:\n",
    "        return v\n",
    "    \n",
    "# map gender\n",
    "data_2019['d01_gender'] = data_2019['d01_gender'].fillna('No Answer')    \n",
    "data_2019['d01_gender'] = data_2019['d01_gender'].apply(lambda x: map_gender(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dd080f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years lived in Somerville. This one is complicated since it was not a coerced data type.\n",
    "\n",
    "def format_years(v):\n",
    "    \"\"\"Map response to 'how long have you lived here?'\"\"\"\n",
    "\n",
    "    # just a number, assume it's years\n",
    "    p = '^([\\.\\d]+)$'\n",
    "    r = re.findall(p, v)\n",
    "    \n",
    "    if len(r) > 0:\n",
    "        return int(float(r[0]))\n",
    "    \n",
    "    # \"3.5 years\"\n",
    "    p = '^([\\.\\d]+) years$'\n",
    "    r = re.findall(p, v)\n",
    "    \n",
    "    if len(r) > 0:\n",
    "        return int(float(r[0]))\n",
    "\n",
    "    # \"30+ years\"\n",
    "    p = '^([\\.\\d]+)\\+ years$'\n",
    "    r = re.findall(p, v)\n",
    "    \n",
    "    if len(r) > 0:\n",
    "        return int(float(r[0]))\n",
    "    \n",
    "    # \"9 months\"\n",
    "    p = '^([\\.\\d]+) months$'\n",
    "    r = re.findall(p, v)\n",
    "    \n",
    "    if len(r) > 0:\n",
    "        return int(float(r[0]) / 12)\n",
    "    \n",
    "    # \"3 weeks\"\n",
    "    p = '^([\\.\\d]+) weeks$'\n",
    "    r = re.findall(p, v)\n",
    "    \n",
    "    if len(r) > 0:\n",
    "        return 0\n",
    "    \n",
    "    # \"6-8 years\"\n",
    "    p = '^([\\.\\d]+)-([\\.\\d]+) years$'\n",
    "    r = re.findall(p, v)\n",
    "    \n",
    "    if len(r) > 0:\n",
    "        return int(float(r[0][1]))\n",
    "    \n",
    "    # \"1 year, 9 months\"\n",
    "    p = '^([\\.\\d]+) year, ([\\.\\d]+) months$'\n",
    "    r = re.findall(p, v)\n",
    "    \n",
    "    if len(r) > 0:\n",
    "        return int(float(r[0][0]))\n",
    "    \n",
    "    # \"3 days\"\n",
    "    p = '^([\\.\\d]+) days$'\n",
    "    r = re.findall(p, v)\n",
    "    \n",
    "    if len(r) > 0:\n",
    "        return 0\n",
    "    \n",
    "    if v == '1 year':\n",
    "        return 1\n",
    "    \n",
    "    if v == '1 month':\n",
    "        return 0\n",
    "    \n",
    "    years_map = {'no_answer': np.nan,\n",
    "             '1 month, two years before from 2010-2012': 2,\n",
    "             '4  months': 0,\n",
    "             '5 years + 10 years before': 15,\n",
    "             '`17 years': 17,\n",
    "             'less than 1 year': 0,\n",
    "             '11years': 11,\n",
    "             '3 generations': np.nan,\n",
    "             '1 year thist ime; 6 years total': 6,\n",
    "             '1 year 2 months': 1,\n",
    "             'too long': np.nan,\n",
    "             '50 +': 50,\n",
    "             ' years': np.nan,\n",
    "             '16+': 16,\n",
    "             '14 years; 11 years now': 14,\n",
    "             '1 year 3 months': 1,\n",
    "             'less than 10 months': 0,\n",
    "             '30+': 30,\n",
    "             '8.5 yesrs': 8.5,\n",
    "             'life long resident': 50,\n",
    "             '1 year this time; 6 years total': 6\n",
    "            }\n",
    "    \n",
    "    if v in years_map.keys():\n",
    "        return years_map[v]\n",
    "\n",
    "# Make sure everything is a string\n",
    "data_2019['d10_how_long_lived_here'] = data_2019['d10_how_long_lived_here'].astype(str)\n",
    "\n",
    "# For some reason '-' was coded as '999'. We need to undo that.\n",
    "data_2019['d10_how_long_lived_here'] = data_2019['d10_how_long_lived_here'].str.replace(\"999\", '-')\n",
    "\n",
    "# Lowercase\n",
    "data_2019['d10_how_long_lived_here'] = data_2019['d10_how_long_lived_here'].str.lower()\n",
    "\n",
    "# remove qualifiers\n",
    "data_2019['d10_how_long_lived_here'] = data_2019['d10_how_long_lived_here'].apply(\n",
    "    lambda x: x[7:] if x.startswith(\"almost \") else x)\n",
    "data_2019['d10_how_long_lived_here'] = data_2019['d10_how_long_lived_here'].apply(\n",
    "    lambda x: x[7:] if x.startswith(\"about \") else x)\n",
    "data_2019['d10_how_long_lived_here'] = data_2019['d10_how_long_lived_here'].apply(\n",
    "    lambda x: x[7:] if x.startswith(\"over \") else x)\n",
    "\n",
    "# apply formatting function\n",
    "data_2019['d10_how_long_lived_here'] = data_2019['d10_how_long_lived_here'].apply(lambda x: format_years(x))\n",
    "\n",
    "# We retain the original column for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dcdc5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housing status\n",
    "\n",
    "def format_housing_status(v):\n",
    "    \"\"\"Map housing status response\"\"\"\n",
    "    \n",
    "    if v == 'Rent':\n",
    "        return v\n",
    "    \n",
    "    elif v == 'Own':\n",
    "        return v\n",
    "    \n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Map housing status. We just want Rent/Own/Other\n",
    "data_2019['d06_housing_status'] = data_2019['d06_housing_status'].apply(lambda x: format_housing_status(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ab8c8998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the city moving in the right direction?\n",
    "\n",
    "city_direction_map = {'Right direction': 'right',\n",
    "                      'Wrong track': 'wrong',\n",
    "                      'Not sure': 'unsure',}\n",
    "\n",
    "data_2019['q05_city_direction'] = data_2019['q05_city_direction'].map(city_direction_map)\n",
    "data_2019['q05_city_direction'].fillna('no_answer', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8f2bb151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language. This is tricky because there's a free response. I mapped most to \"other\"\n",
    "\n",
    "data_2019['d03_language'] = data_2019['d03_language'].str.lower()\n",
    "\n",
    "data_2019['d03_english'] = pd.to_numeric(data_2019['d03_language'].str.contains('english') * 1)\n",
    "data_2019['d03_spanish'] = pd.to_numeric(data_2019['d03_language'].str.contains('spanish') * 1)\n",
    "data_2019['d03_portuguese'] = pd.to_numeric(data_2019['d03_language'].str.contains('portuguese') * 1)\n",
    "\n",
    "searchfor = ['mandarin', 'chinese', 'contonese']\n",
    "data_2019['d03_chinese'] = pd.to_numeric(data_2019['d03_language'].str.contains('|'.join(searchfor)) * 1)\n",
    "\n",
    "searchfor = ['arabic', 'greek', 'french', 'punjabi', 'amharic', \n",
    "             'gujrati', 'nepali', 'tigrinya', 'polish', 'filipino',\n",
    "             'italian', 'japanese', 'russian', 'haitian creole', 'kreole', 'romanian',\n",
    "             'slovac', 'vietnnamese', 'esperanto', 'hebrew', 'bulgarian', 'latin',\n",
    "            'persian', 'romanian']\n",
    "data_2019['d03_other'] = pd.to_numeric(data_2019['d03_language'].str.contains('|'.join(searchfor)) * 1)\n",
    "\n",
    "data_2019.drop('d03_language', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1aad0234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an enthicity column with Hispanic / not Hispanic\n",
    "\n",
    "# format string\n",
    "data_2019['d04_race'] = data_2019['d04_race'].str.lower()\n",
    "\n",
    "\n",
    "searchfor = ['hispanic', 'puerto rican']\n",
    "data_2019['d04_ethnicity'] = pd.to_numeric(data_2019['d04_race'].str.contains('|'.join(searchfor)) * 1)\n",
    "    \n",
    "# ethnicity hook for population balancing\n",
    "#data_2019['eth_hooks'] = data_2019.apply(\n",
    "#    lambda row: 'eth_hispanic' if row['d04_eth_hispanic'] >= 1 else 'eth_not_hispanic', axis=1)\n",
    "\n",
    "\n",
    "    \n",
    "# Race is also used in balancing hooks. People can have multiple responses and we want to keep track of \"more than one race\".\n",
    "# So as an intermediate step we break out indicators for each race in (white, aa, asian, other)\n",
    "\n",
    "\n",
    "# Break out white, black, asian\n",
    "data_2019['d04_race_white'] = pd.to_numeric(data_2019['d04_race'].str.contains('white') * 1)\n",
    "data_2019['d04_race_aa'] = pd.to_numeric(data_2019['d04_race'].str.contains('black') * 1)\n",
    "data_2019['d04_race_asian'] = pd.to_numeric(data_2019['d04_race'].str.contains('asian') * 1)\n",
    "\n",
    "# Map everything else to other\n",
    "searchfor = ['jewish', 'american indian', 'portuguese', 'cape verdean', \n",
    "             'middle eastern', 'east indian', 'biracial', 'arab', 'brazilian']\n",
    "data_2019['d04_race_other'] = pd.to_numeric(data_2019['d04_race'].str.contains('|'.join(searchfor)) * 1)\n",
    "\n",
    "# We need to define a column that maps to population hooks.\n",
    "def get_race_hooks(row):\n",
    "    race_cols = ['d04_race_aa', 'd04_race_asian', 'd04_race_white', 'd04_race_other']\n",
    "    if sum(row[race_cols]) > 1:\n",
    "        return 'two_or_more'\n",
    "    if row['d04_race_aa'] > 0:\n",
    "        return 'aa'\n",
    "    if row['d04_race_asian'] > 0:\n",
    "        return 'asian'\n",
    "    if row['d04_race_other'] > 0:\n",
    "        return 'other'\n",
    "    if row['d04_race_white'] > 0:\n",
    "        return 'white'\n",
    "    else:\n",
    "        return 'No Answer'\n",
    "    \n",
    "data_2019['race_hooks'] = data_2019.apply(lambda row: get_race_hooks(row), axis=1)\n",
    "\n",
    "\n",
    "# we retain the original column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "feea9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Household income. Map to buckets for population balancing.\n",
    "\n",
    "hhi_map = {'Less than $10,000': '1',\n",
    "           '$10,000 to $24,999': '2',\n",
    "           '$25,000 to $49,999': '3',\n",
    "           '$50,000 to 74,999': '4',\n",
    "           '$75,000 to $99,999': '5',\n",
    "           '$100,000 to $149,999': '6',\n",
    "           '$150,000 to 200,000': '7',\n",
    "           '$200,000 or more': '8'}\n",
    "\n",
    "data_2019['d08_hhi_buckets'] = data_2019['d08_hhi'].map(hhi_map)\n",
    "\n",
    "# We retain the original column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0489bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to binary datatype for children, plan to move, is student\n",
    "\n",
    "data_2019['d05_num_children'] = pd.to_numeric(data_2019['d05_num_children'].map({'Yes': 1, 'No': 0}))\n",
    "data_2019['d07_plan_to_move'] = pd.to_numeric(data_2019['d07_plan_to_move'].map({'Yes': 1, 'No': 0}))\n",
    "data_2019['d09_is_student'] = pd.to_numeric(data_2019['d09_is_student'].map({'Yes': 1, 'No': 0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d34f6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age also gets mapped to buckets for population balancing, but we want to retain the original column as well\n",
    "\n",
    "def map_age(v):\n",
    "    \"\"\"Define age buckets\"\"\"\n",
    "    if v == 17:\n",
    "        return \"17 Years\"\n",
    "    elif v <= 24:\n",
    "        return \"18 to 24 Years\"\n",
    "    elif v <= 34:\n",
    "        return \"25 to 34 Years\"\n",
    "    elif v <= 44:\n",
    "        return \"35 to 44 Years\"\n",
    "    elif v <= 54:\n",
    "        return \"45 to 54 Years\"\n",
    "    elif v <= 64:\n",
    "        return \"55 to 64 Years\"\n",
    "    elif v <= 74:\n",
    "        return \"65 to 74 Years\"\n",
    "    else:\n",
    "        return \"75 Years & Over\"\n",
    "    \n",
    "\n",
    "\n",
    "# map age since we need it for balancing\n",
    "data_2019['d02_age'] = pd.to_numeric(data_2019['d02_age'])\n",
    "data_2019['d02_age'] = data_2019['d02_age'].apply(lambda x: map_age(x))\n",
    "data_2019['d02_age'] = data_2019['d02_age'].fillna('No Answer')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9a6e70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transportation.\n",
    "# These can have compound answers that we need to break out into indicators.\n",
    "\n",
    "# the transportation questions return a list of vehicles. Break into indicator columns.\n",
    "data_2019['d11_car'] = pd.to_numeric(data_2019['d11_transportation_mode'].str.contains('Car') * 1)\n",
    "data_2019['d11_walk'] = pd.to_numeric(data_2019['d11_transportation_mode'].str.contains('Walk') * 1)\n",
    "data_2019['d11_bike'] = pd.to_numeric(data_2019['d11_transportation_mode'].str.contains('Bike') * 1)\n",
    "data_2019['d11_public'] = pd.to_numeric(data_2019['d11_transportation_mode'].str.contains('Public') * 1)\n",
    "\n",
    "data_2019.drop('d11_transportation_mode', axis=1, inplace=True)\n",
    "\n",
    "data_2019['d12_car'] = pd.to_numeric(data_2019['d12_transportation_month'].str.contains('Car') * 1)\n",
    "data_2019['d12_walk'] = pd.to_numeric(data_2019['d12_transportation_month'].str.contains('Walk') * 1)\n",
    "data_2019['d12_bike'] = pd.to_numeric(data_2019['d12_transportation_month'].str.contains('Bike') * 1)\n",
    "data_2019['d12_public'] = pd.to_numeric(data_2019['d12_transportation_month'].str.contains('Public') * 1)\n",
    "\n",
    "data_2019.drop('d12_transportation_month', axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "28545168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data\n",
    "\n",
    "data_2019.set_index('id', inplace=True)\n",
    "\n",
    "data_2019.to_csv('../data/processed/data_2019_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8730d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
