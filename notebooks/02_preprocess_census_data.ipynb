{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d710d75c",
   "metadata": {},
   "source": [
    "# Preprocess census data\n",
    "\n",
    "Load census data and get into a format where we can do population weighting by gender, HHI, race, and ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "197b16cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4448c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load census data\n",
    "\n",
    "age_data = pd.read_csv('../data/raw/Age by Nativity.csv')\n",
    "hhi_data = pd.read_csv('../data/raw/Household Income.csv')\n",
    "race_data = pd.read_csv('../data/raw/Race and Ethnicity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1b740092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Race</th>\n",
       "      <th>Race</th>\n",
       "      <th>ID Ethnicity</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>ID Year</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hispanic Population Moe</th>\n",
       "      <th>Geography</th>\n",
       "      <th>ID Geography</th>\n",
       "      <th>Slug Geography</th>\n",
       "      <th>Population</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>White Alone</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>Somerville, MA</td>\n",
       "      <td>16000US2562535</td>\n",
       "      <td>somerville-ma</td>\n",
       "      <td>55183</td>\n",
       "      <td>0.682063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>White Alone</td>\n",
       "      <td>1</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>Somerville, MA</td>\n",
       "      <td>16000US2562535</td>\n",
       "      <td>somerville-ma</td>\n",
       "      <td>6113</td>\n",
       "      <td>0.075557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Black or African American Alone</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>720.0</td>\n",
       "      <td>Somerville, MA</td>\n",
       "      <td>16000US2562535</td>\n",
       "      <td>somerville-ma</td>\n",
       "      <td>4534</td>\n",
       "      <td>0.056040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Black or African American Alone</td>\n",
       "      <td>1</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>325.0</td>\n",
       "      <td>Somerville, MA</td>\n",
       "      <td>16000US2562535</td>\n",
       "      <td>somerville-ma</td>\n",
       "      <td>451</td>\n",
       "      <td>0.005574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>American Indian &amp; Alaska Native Alone</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Somerville, MA</td>\n",
       "      <td>16000US2562535</td>\n",
       "      <td>somerville-ma</td>\n",
       "      <td>112</td>\n",
       "      <td>0.001384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Race                                   Race  ID Ethnicity  \\\n",
       "0        0                            White Alone             0   \n",
       "1        0                            White Alone             1   \n",
       "2        1        Black or African American Alone             0   \n",
       "3        1        Black or African American Alone             1   \n",
       "4        2  American Indian & Alaska Native Alone             0   \n",
       "\n",
       "                Ethnicity  ID Year  Year  Hispanic Population Moe  \\\n",
       "0  Not Hispanic or Latino     2019  2019                   1314.0   \n",
       "1      Hispanic or Latino     2019  2019                   1152.0   \n",
       "2  Not Hispanic or Latino     2019  2019                    720.0   \n",
       "3      Hispanic or Latino     2019  2019                    325.0   \n",
       "4  Not Hispanic or Latino     2019  2019                     81.0   \n",
       "\n",
       "        Geography    ID Geography Slug Geography  Population     share  \n",
       "0  Somerville, MA  16000US2562535  somerville-ma       55183  0.682063  \n",
       "1  Somerville, MA  16000US2562535  somerville-ma        6113  0.075557  \n",
       "2  Somerville, MA  16000US2562535  somerville-ma        4534  0.056040  \n",
       "3  Somerville, MA  16000US2562535  somerville-ma         451  0.005574  \n",
       "4  Somerville, MA  16000US2562535  somerville-ma         112  0.001384  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3ceedc",
   "metadata": {},
   "source": [
    "Map race names to match the survey. Names don't have to be identical, but identify the right categories:\n",
    "\n",
    "white, black, asian, other (inc Native Hawaiian), two_or_more_races\n",
    "\n",
    "Map ethnicity to hispanic / not hispanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0c3a9bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Race \n",
    "\n",
    "race_data = race_data[race_data[\"Year\"]==2019]\n",
    "\n",
    "# change value names\n",
    "race_map = {'White Alone': 'white',\n",
    "            'Black or African American Alone': 'aa',\n",
    "            'Asian Alone': 'asian',\n",
    "            'American Indian & Alaska Native Alone': 'other',\n",
    "            'Native Hawaiian & Other Pacific Islander Alone': 'other',\n",
    "            'Some Other Race Alone': 'other',\n",
    "            'Two or More Races': 'two_or_more'}\n",
    "\n",
    "race_data['race_mapped'] = race_data['Race'].map(race_map)\n",
    "\n",
    "# Ethnicity\n",
    "\n",
    "# change value names\n",
    "eth_map = {'Hispanic or Latino': 'hispanic',\n",
    "           'Not Hispanic or Latino': 'not_hispanic'}\n",
    "\n",
    "race_data['eth_mapped'] = race_data['Ethnicity'].map(eth_map)\n",
    "\n",
    "\n",
    "# create weights df\n",
    "race_eth_weights = race_data[['race_mapped', 'eth_mapped', 'share']]\n",
    "race_eth_weights = race_eth_weights.groupby(['race_mapped', 'eth_mapped']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3d03e",
   "metadata": {},
   "source": [
    "For age data we need to group native born and non native born. We can just sum the populations and shares.\n",
    "\n",
    "Then we need to decimate 5-17 so we can get just 17 (assume equal age dist in this group), group 55-64, eliminated Under 5, and rebalance to remaining groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "797b68e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "\n",
    "# filter down to 2019 for age data\n",
    "age_data = age_data[age_data['Year'] == 2019]\n",
    "\n",
    "# group by age (aggregate out place of birth)\n",
    "age_data = age_data.groupby('Age').sum()[['share']]\n",
    "\n",
    "# divide the 5 - 17 share by the number of years\n",
    "share_5_17 = age_data.loc['5 to 17 Years', 'share']\n",
    "share_17  = share_5_17 / (17 - 5)\n",
    "\n",
    "# group 55 - 64\n",
    "rows_55_64 = ['55 to 59 Years', '60 & 61 Years', '62 to 64 Years']\n",
    "share_55_64 = age_data.loc[rows_55_64, 'share'].sum()\n",
    "\n",
    "# add rows for 17 and 55 - 64\n",
    "age_data.loc['17 Years'] = share_17\n",
    "age_data.loc['55 to 64 Years'] = share_55_64\n",
    "\n",
    "# drop under 5, 5-17, all 55-64 subgroups\n",
    "age_data.drop(rows_55_64, inplace=True)\n",
    "age_data.drop(['5 to 17 Years', 'Under 5 Years'], inplace=True)\n",
    "\n",
    "# rebalance to remaining groups\n",
    "age_data['share'] = age_data['share'] / sum(age_data['share'])\n",
    "\n",
    "age_weights = age_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "749c1503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Household income\n",
    "\n",
    "hhi_data = hhi_data[hhi_data['Year']==2019]\n",
    "hhi_data = hhi_data[hhi_data['Geography']=='Somerville, MA']\n",
    "\n",
    "hhi_map = {'< $10,000': 'hhi_1',\n",
    "           '$10,000-$14,999': 'hhi_2',\n",
    "           '$15,000-$19,999': 'hhi_2',\n",
    "           '$20,000-$24,999': 'hhi_2',\n",
    "           '$25,000-$29,999': 'hhi_3', \n",
    "           '$30,000-$34,999': 'hhi_3',\n",
    "           '$35,000-$39,999': 'hhi_3', \n",
    "           '$40,000-$44,999': 'hhi_3', \n",
    "           '$45,000-$49,999': 'hhi_3',\n",
    "           '$50,000-$59,999': 'hhi_4', \n",
    "           '$60,000-$74,999': 'hhi_4', \n",
    "           '$75,000-$99,999': 'hhi_5',\n",
    "           '$100,000-$124,999': 'hhi_6', \n",
    "           '$125,000-$149,999': 'hhi_6', \n",
    "           '$150,000-$199,999': 'hhi_7',\n",
    "           '$200,000+': 'hhi_8'}\n",
    "\n",
    "hhi_data['hhi_mapped'] = hhi_data['Household Income Bucket'].map(hhi_map)\n",
    "\n",
    "hhi_weights = hhi_data.groupby('hhi_mapped').sum()[['share']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e48d55d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't need to import data for gender. Somerville is listed as 50/50 split between male and female. \n",
    "# Nonbinary is not accounted for in the census so I'm using a national avg of 0.5%.\n",
    "gender_weights = pd.DataFrame({'gender': ['gender_Male', 'gender_Female', 'gender_Nonbinary'], 'share': [.4975, .4975, .005]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "875e4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose and concatenate\n",
    "\n",
    "hhi_t = hhi_weights.set_index('hhi_mapped').T\n",
    "gender_t = gender_weights.set_index('gender').T\n",
    "age_t = age_weights.set_index('Age').T\n",
    "\n",
    "age_t.columns = ['age_' + c for c in age_t.columns]\n",
    "\n",
    "# we can do better than marginal values for race and ethnicity since we have the breakdown for Somerville.\n",
    "race_eth_t = race_eth_weights.set_index(['race_mapped', 'eth_mapped']).T\n",
    "race_eth_t.columns = ['race_ethnicity_({0}, {1})'.format(c[0], c[1]) for c in race_eth_t.columns]\n",
    "\n",
    "target_population = (pd.concat([hhi_t, gender_t, race_eth_t, age_t], axis=1) * 75000).T.astype(int)\n",
    "target_population = target_population.reset_index().rename(columns={'index': 'demo', 'share': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "76fdad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "target_population.to_csv('../data/processed/target_populations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b30994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
